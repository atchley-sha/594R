---
title: "HW #4: Analyze real-world emissions data RESUBMISSION"
subtitle: "See 3 & 6"
author: Hayden Atchley
date: "`r Sys.Date()`"
mainfont: Gentium Book Basic
output:
  bookdown::pdf_document2:
    toc: false
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

pacman::p_load(tidyverse, kableExtra, zfit, broom, ggthemes, DescTools)
```


```{r}
feat <- read_csv("data/feat.class.example.csv")
```

# 1

```{r}
#| em-density,
#| fig.cap="Emissions density by date.",
#| fig.pos="H"

feat1 <- feat %>% 
	replace_na(list(NO_g_kg = 0, NO2_g_kg = 0, HC_g_kg = 0, CO_g_kg = 0)) %>% 
	mutate(NOx_g_kg = NO_g_kg + NO2_g_kg) %>% 
	select(DATE, CO_g_kg, HC_g_kg, NOx_g_kg, location, VEH_ID) %>% 
	pivot_longer(-c(DATE, location, VEH_ID), names_to = "pollutant", values_to = "amount") %>% 
	mutate(pollutant = str_remove(pollutant, "_.+"))

feat1 %>% 
	ggplot() +
	geom_density(aes(x = amount, color = pollutant)) +
	facet_wrap(~DATE) +
	theme_pander() +
	lims(x = c(NA,100),
			 y = c(NA, 0.3)) +
	labs(x = "Emmission Rate (g / kg fuel)",
			 y = "kernel density",
			 color = "Pollutant")
```

## 1.1

```{r}
feat1 %>% 
	group_by(location, pollutant) %>% 
	summarise(max_emisions = max(amount), median_emissions = median(amount)) %>% 
	mutate("max / median" = max_emisions / median_emissions) %>% 
	kbl(booktabs = TRUE, digits = 2, linesep = "") %>% 
	kable_styling(latex_options = "HOLD_position")
```

## 1.2

Looking at Figure \@ref(fig:em-density), NOx appears to have quite a skewed distribution, though CO has a few extreme outliers.

# 2

```{r}
#| fig.height=3

feat2 <- feat1 %>% 
	select(VEH_ID, pollutant, amount) %>% 
	pivot_wider(names_from = pollutant, values_from = amount)

feat2 %>% 
	ggplot(aes(x = CO, y = HC)) +
	geom_point() +
	geom_smooth(method = 'lm') +
	theme_pander()
```

```{r}
#| fig.height=3

feat2 %>% 
	ggplot(aes(x = CO, y = NOx)) +
	geom_point() +
	geom_smooth(method = 'lm') +
	theme_pander()
```

```{r}
fit2 <- feat2 %>% 
	zlm(CO ~ NOx + HC) %>% 
	summary()

fit2 %>% 
	tidy() %>% 
	kbl(booktabs = TRUE, digits = c(0,2,2,2,3)) %>% 
	footnote(paste0("$R^2$ = ", fit2$adj.r.squared %>% round(3)),
					 general_title = "",
					 escape = FALSE) %>% 
	kable_styling(latex_options = "HOLD_position")
```

While it appears that vehicles with more CO emissions also have more NOx and HC emissions (both of these slopes/coefficients are positive), the $R^2$ value is quite low. There could be many other factors explaining the variance in emission rates.

# 3 (3.1)

**Previously I didn't answer this question**

The theory behind I/M programs is good, in that vehicles with high emissions are kept from operation. However, as mentioned, this creates issues with equity, where these programs impact lower income individuals more than higher income individuals. Perhaps one of the main reasons for this is due to the age of the vehicles owned based on income. Newer vehicles are more fuel efficient as well as lower-emitting than older vehicles (at least as a rule), especially as emissions standards continue to get stricter. Newer vehicles are also significantly more expensive than older vehicles, and so are less likely to be owned by lower income individuals.

But this does not wholly discount the benefit of I/M programs. In fact, I'd argue these programs (or at least the concept of them) are a good thing so long as equity can be addressed properly. Perhaps, though, funds that would have gone to I/M programs could be better used as a subsidy for low-income individuals to purchase more climate-friendly vehicles. Though this doesn't address the question of what to do with high-emitting vehicles directly, increasing the gas/diesel tax would discourage driving as much (lowering emissions), and then the excess funds could again be used as subsidies for low- to no-emitting vehicles.


# 4

```{r}
feat1 %>% 
	filter(pollutant == "CO") %>% 
	select(-pollutant, -VEH_ID) %>% 
	group_by(DATE, location) %>% 
	summarise(
		name = names(MeanCI(amount, conf.level = 0.9)),
		value = MeanCI(amount, conf.level = 0.9)) %>% 
	pivot_wider() %>% 
	kbl(booktabs = TRUE, digits = c(0,0,2,2,1)) %>% 
	kable_styling(latex_options = "HOLD_position")
```

```{r}
#| mean-conf,
#| fig.cap = "CO emission rate for each day. The bars show the mean and 90% confidence interval for the mean.",
#| fig.pos = "H",
#| fig.height = 3

feat1 %>% 
	filter(pollutant == "CO") %>% 
	select(-pollutant, -VEH_ID) %>% 
	ggplot(aes(y = DATE, x = amount, fill = location)) +
	geom_violin() +
	stat_summary(
		fun.data = function(x) MeanCI(x, conf.level = 0.9) %>% 
			`names<-`(c("y", "ymin", "ymax")),
		geom = "errorbar",
		width = 0.3) +
	stat_summary(fun = mean, geom = "point") +
	theme_pander() +
	xlim(NA, 200) +
	labs(
		x = "CO Emission Rate (g / kg fuel)",
		y = "Date",
		fill = "Location")
```

The table below shows a Tukey-Kramer test for multiple variance based on emissions test location. None of the _p_-values indicate significant results, so we can't conclude that the means are different from each other.

```{r}
feat1 %>% 
	filter(pollutant == "CO") %>% 
	aov(amount ~ location, data = .) %>% 
	TukeyHSD() %>% 
	tidy() %>% 
	select(-term, -null.value)
```

## 4.1

Assuming the re-sampling method refers to a permutation/randomization test, the main advantage is that no assumptions need to be made regarding skewness, normality, or outliers. The main disadvantage is that it is computationally intensive to compare all permutations of the data points, especially when the data sets are large. Often a smaller subset of permutations is performed, which can usually offer a good approximation of the full permutation test.

# 5



# 6

**Previously I used _all_ samples as if they were independent rather than the means at each location.**

```{r}
site <- read_csv("data/CO.site.average.date.2023.csv") %>% 
	mutate(DATE = as.Date(DATE, format = "%m/%d/%Y")) %>% 
	group_by(location) %>% 
	summarise(mean_loc = mean(mean_CO_g_kg))
```

Because there were multiple data points at each location, and multiple locations, the data points are not necessarily all random and independent. The measured values at each location are more likely to correlate with each other for any number of potential reasons, including measurement techniques, outside air quality, geographic distribution of vehicle types and sizes, etc. In short, there are many potential variables that a given location would have constant, but could affect the measured emissions. Therefore, each of the daily means are _not_ from the same population, so shouldn't directly be compared between locations.

However, the mean emissions at each _location_ is in fact random and independent, as now the effect these previously-mentioned variables can be captured, that is, the effect on the _location_ means. We therefore take the mean emissions at each location:
```{r}
site %>%
	`names<-`(c("Location", "Mean Emissions")) %>% 
	kbl(digits = 1, booktabs = TRUE, linesep = "") %>% 
	kable_styling(latex_options = "HOLD_position")
```
and can now find the mean of _these_ values to estimate the mean emission rate for all of Utah County (with 95% confidence interval):

```{r}
MeanCI(site$mean_loc) %>% 
	bind_rows() %>% 
	kbl(digits = 1, booktabs = TRUE) %>% 
	kable_styling(latex_options = "HOLD_position")
```

## 6.1

The random, independent variable is as previously mentioned the mean CO emission rate at each _location_. These values can be assumed to be independent and random, but the _daily_ emission rates cannot, as the rates at each location will be correlated with each other.